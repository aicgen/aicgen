# Example AICGEN Configuration File
#
# LOCATION: This file should be placed at:
#   - Windows: C:\Users\YourUsername\.aicgen\config.yml
#   - Linux/Mac: ~/.aicgen/config.yml
#
# INSTALLATION:
#   Windows:
#     mkdir C:\Users\%USERNAME%\.aicgen
#     copy config.example.yml C:\Users\%USERNAME%\.aicgen\config.yml
#
#   Linux/Mac:
#     mkdir -p ~/.aicgen
#     cp config.example.yml ~/.aicgen/config.yml
#
# Configuration priority: Environment Variables > User Config > Defaults

# GitHub repository configuration
github:
  owner: aicgen
  repo: aicgen-data

# AI Provider Configuration
# Customize models, timeouts, and behavior for different AI providers
ai:
  # Google Gemini Configuration
  gemini:
    # Model: Use latest Gemini 2.0 or 2.5 models
    # See: https://ai.google.dev/gemini-api/docs/models
    model: gemini-2.0-flash-exp
    # Available models:
    #   - gemini-2.5-flash (latest, recommended)
    #   - gemini-2.5-pro (most capable, slower)
    #   - gemini-2.0-flash-exp (experimental, fast)

    # Request timeout in milliseconds
    timeout: 30000

    # Maximum retry attempts for failed requests
    maxRetries: 3

    # Maximum output tokens
    maxTokens: 8192

  # Anthropic Claude Configuration
  claude:
    # Model: Use Claude 3.5 Sonnet or Opus
    # See: https://docs.anthropic.com/en/docs/about-claude/models
    model: claude-3-5-sonnet-20241022
    # Available models:
    #   - claude-3-5-sonnet-20241022 (best balance, recommended)
    #   - claude-3-opus-20240229 (most capable, expensive)
    #   - claude-3-haiku-20240307 (fastest, cheapest)

    # Request timeout in milliseconds
    timeout: 30000

    # Maximum retry attempts
    maxRetries: 3

    # Maximum output tokens
    maxTokens: 8096

    # Temperature (0-1): Lower = more focused, Higher = more creative
    temperature: 0.7

  # OpenAI Configuration
  openai:
    # Model: Use GPT-4o or GPT-4 Turbo
    # See: https://platform.openai.com/docs/models
    model: gpt-4o
    # Available models:
    #   - gpt-4o (latest, recommended)
    #   - gpt-4-turbo (high capability)
    #   - gpt-4 (most capable, expensive)
    #   - gpt-3.5-turbo (fast, cheaper)

    # Request timeout in milliseconds
    timeout: 30000

    # Maximum retry attempts
    maxRetries: 3

    # Maximum output tokens
    maxTokens: 4096

    # Temperature (0-2): Lower = more focused, Higher = more creative
    temperature: 0.7

  # Sub-Agent Configuration
  # These are specialized agents for code review tasks
  subAgents:
    # Guideline Checker - Verifies code follows project guidelines
    guidelineChecker:
      model: claude-opus-4-5
      # Use lower temperature for strict guideline checking
      temperature: 0.3

    # Architecture Reviewer - Reviews architectural decisions
    architectureReviewer:
      model: claude-sonnet-4-5
      # Balanced temperature for architecture review
      temperature: 0.5

    # Security Auditor - Identifies security vulnerabilities
    securityAuditor:
      model: claude-opus-4-5
      # Lower temperature for thorough security analysis
      temperature: 0.3

# Alternative: Use environment variables instead
# Export these in your shell profile (.bashrc, .zshrc, etc.):
#
# # Gemini
# export AICGEN_GEMINI_MODEL=gemini-2.5-pro
# export AICGEN_GEMINI_TIMEOUT=60000
# export AICGEN_GEMINI_MAX_RETRIES=5
#
# # Claude
# export AICGEN_CLAUDE_MODEL=claude-3-opus-20240229
# export AICGEN_CLAUDE_TEMPERATURE=0.5
#
# # OpenAI
# export AICGEN_OPENAI_MODEL=gpt-4-turbo
# export AICGEN_OPENAI_TEMPERATURE=0.8
#
# # Sub-Agents
# export AICGEN_SUBAGENT_GUIDELINE_MODEL=claude-opus-4-5
# export AICGEN_SUBAGENT_GUIDELINE_TEMP=0.2
